{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas e arquivos necessarios\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "from network_architectures import dense_autoencoder\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "%load_ext tensorboard\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#   Faz o download do fashion_mnist da base de dados do keras\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "#   Carrega esse dataset, ja separando entre dados de treinamento e dados de teste\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#   Podemos verificar o formato desses arquivos\n",
    "train_images.shape\n",
    "test_images.shape\n",
    "train_labels.shape\n",
    "test_labels.shape\n",
    "\n",
    "#   Segunda parte - processar os dados -----------------------------------------\n",
    "#   Em seguida, precisamos processar esses dados. Nesse caso, o processamento se resume a\n",
    "#   limitar o valor de cada pixel das imagens no intervalo [0,1]. Fazemos isso dividindo por 255\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Terceira parte - Definir o modelo e fazer o treinamento --------------------\n",
    "\n",
    "#   Carregamos a arquitetura do nosso modelo do nosso arquivo de arquiteturas. Isso deixa o codigo\n",
    "#   bem modular e limpo\n",
    "model = dense_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Compilamos o nosso modelo. Compilar significa dizer qual a funcao custo e otimizador vamos utilizar (entre outras coisinhas)\n",
    "\n",
    "#   Nesse caso, o otimizador eh o \"Adam\". A funcao custo eh uma funcao mse\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               50960     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 101,200\n",
      "Trainable params: 101,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Dessa vez, antes de proseguirmos com o treinamento, vamos criar um callback.\n",
    "#   O callback serve para que o keras faca coisas entre epocas, como por exemplo,\n",
    "#   salvar o melhor modelo. Faremos um callback para que ele salve a melhor epoca,\n",
    "#   e mude o \"learning rate\" dependendo da epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   um learning rate scheduler muda o learning rate de acordo com qual a epoca atual\n",
    "#   nosso learning scheduler simplesmente muda a taxa ao passar de 10 epocas\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.01,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "learning_schedule = keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este callback faz com que o treinamento acabe mais rapidamente, caso a função custo não esteja mais sendo minimizada\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Para salvarmos a melhor epoca, usamos o callback de ModelCheckpoint\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('model_checkpoint.hdf5',\n",
    "                    monitor='val_loss',\n",
    "                    verbose=2,\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False,\n",
    "                    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Para vizualizarmos melhor o treinamento do modelo, usaremos o Tensorboard\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   criamos o callback para passar para o metodo .fit\n",
    "callback = [learning_schedule, model_checkpoint, tensorboard, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0352 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01160, saving model to model_checkpoint.hdf5\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01160 to 0.01129, saving model to model_checkpoint.hdf5\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01129 to 0.01103, saving model to model_checkpoint.hdf5\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01103 to 0.01082, saving model to model_checkpoint.hdf5\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01082\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01082 to 0.01063, saving model to model_checkpoint.hdf5\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01063\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01063 to 0.01061, saving model to model_checkpoint.hdf5\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01061 to 0.01060, saving model to model_checkpoint.hdf5\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01060 to 0.01055, saving model to model_checkpoint.hdf5\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01055 to 0.01036, saving model to model_checkpoint.hdf5\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01036 to 0.01031, saving model to model_checkpoint.hdf5\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01031\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01031\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01031 to 0.01012, saving model to model_checkpoint.hdf5\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01012\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01012\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01012 to 0.01007, saving model to model_checkpoint.hdf5\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01007\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01007 to 0.00987, saving model to model_checkpoint.hdf5\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00987 to 0.00982, saving model to model_checkpoint.hdf5\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00982 to 0.00979, saving model to model_checkpoint.hdf5\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00979\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00979 to 0.00959, saving model to model_checkpoint.hdf5\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00959\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00959\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00959\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00959\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00959\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00959\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00959\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00959 to 0.00958, saving model to model_checkpoint.hdf5\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00958 to 0.00952, saving model to model_checkpoint.hdf5\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00952\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00952 to 0.00950, saving model to model_checkpoint.hdf5\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00950\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00950 to 0.00944, saving model to model_checkpoint.hdf5\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00944\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00944 to 0.00940, saving model to model_checkpoint.hdf5\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00940\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00940 to 0.00935, saving model to model_checkpoint.hdf5\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00935 to 0.00925, saving model to model_checkpoint.hdf5\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00925\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00925\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00925\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00925\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00925\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00925\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00925\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00925\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00925\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00925 to 0.00917, saving model to model_checkpoint.hdf5\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00917\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00917\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00917 to 0.00913, saving model to model_checkpoint.hdf5\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00913 to 0.00913, saving model to model_checkpoint.hdf5\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00913 to 0.00908, saving model to model_checkpoint.hdf5\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00908\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00908\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00908\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00908 to 0.00907, saving model to model_checkpoint.hdf5\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00907\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00907 to 0.00906, saving model to model_checkpoint.hdf5\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00906\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00906\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00906 to 0.00897, saving model to model_checkpoint.hdf5\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00897\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00897\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00897\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00897 to 0.00895, saving model to model_checkpoint.hdf5\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00895\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00895\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00895\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00895\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00895 to 0.00889, saving model to model_checkpoint.hdf5\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00889\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00889\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00889\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00889\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00889\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00889 to 0.00874, saving model to model_checkpoint.hdf5\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00874\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00874\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00874\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00874\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00874\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00874\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00874\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00874\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00874\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00874\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00874\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00874\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00874\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00874\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00874\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00874\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00874 to 0.00870, saving model to model_checkpoint.hdf5\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00870\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00870 to 0.00870, saving model to model_checkpoint.hdf5\n"
     ]
    }
   ],
   "source": [
    "#   Agora vamos enfim treinar o modelo. Usamos o metodo \"fit\", passando como parametro nossos dados de treino, teste, e por quantas epocas\n",
    "#   Esse metodo retorna os dados mostrados durante o treinamento, e em geral e interessante salva-los.\n",
    "\n",
    "fit_history = model.fit(train_images, train_images, validation_data=(test_images, test_images), epochs=100, batch_size=64, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e486f9e54307af24\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e486f9e54307af24\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Voce pode vizualizar diversor gráficos e estatísticas sobre o treinamento usando o tensorboard\n",
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Quarta parte - Salvar o modelo e outros dados --------------------\n",
    "#   Neste ponto, nosso modelo ja esta treinado. Em geral, so queremos treinar o modelo uma unica vez, pois demora muito.\n",
    "#   Vamos entao salvar esse modelo, junto com os dados de treinamento, no disco. Assim, se precisarmos usar ele novamente,\n",
    "#   so precisamos carrega-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Vamos primeiro salvar o historico de treinamento. Para isso, criaremos um dataframe no pandas (por ser mais facil de trabalhar assim)\n",
    "fit_history_df = pandas.DataFrame(fit_history.history)\n",
    "\n",
    "#   Com isso podemos salvar esses dados no disco diretamente\n",
    "with open('fit_history.csv', mode='w') as f:\n",
    "    fit_history_df.to_csv(f)\n",
    "#   Reparar que um arquivo csv foi salvo no disco. Da uma olhadinha nesse arquivo depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1422"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Em seguida, vamos salvar o modelo. Para isso, salvamos tanto a arquitetura quanto os pesos calculados.\n",
    "#   A arquitetura do modelo podemos salvar como um arquivo json, com a funcao\n",
    "model_json_string = model.to_json()\n",
    "open('architecture.json', 'w').write(model_json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Eh importante notar que estamos salvando a ULTIMA EPOCA do modelo, e que ela nao necessariamente sera a melhor.\n",
    "#   Para salvarmos a melhor epoca do modelo, precisamos configurar um \"callback\" no keras. Faremos isso em outro tutorial\n",
    "\n",
    "#   Agora um arquivo json foi salvo. Da uma olhadinha nesse arquivo tbm\n",
    "#   Ta na hora de salvar os pesos. Isso eh feito com a funcao\n",
    "model.save_weights('model_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Agora esse arquivo .h5 tbm foi salvo no disco. Com isso temos todo o nosso modelo salvo no disco, e nao precisaremos treina-lo novamente\n",
    "#   Nosso arquivo de treinamento acaba por aqui. Agora vamos analisar o modelo no outro arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
